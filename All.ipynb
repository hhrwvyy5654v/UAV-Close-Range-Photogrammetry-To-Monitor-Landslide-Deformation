{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过张正友标定法获取相机参数\n",
    "#### 步骤\n",
    "```\n",
    "1.准备标定板：使用一个已知尺寸的标定板（通常是黑白棋盘格），并在标定板上标记出若干个特征点。\n",
    "2.拍摄图像：将标定板放置在不同的位置姿态下拍摄多张图像，并记录每张图像对应的相机姿态（即相机位姿）。\n",
    "3.提取角点：对每张图像进行角点提取，即找到标定板上的特征点在图像中的对应位置。\n",
    "4.计算相机姿态：通过已知的标定板尺寸和提取的角点，计算每张图像对应的相机位姿。\n",
    "5.标定相机：使用相机标定公式，计算出相机的内参矩阵和畸变系数。\n",
    "6.评估标定结果：使用标定结果评估指标（如重投影误差）来评估标定结果的准确性。\n",
    "需要注意的是，该方法需要至少使用10张以上的图像才能稳健地标定相机。此外，标定板的布局和大小也会对标定结果产生影响。\n",
    "```\n",
    "#### 注意\n",
    "```\n",
    "1.标定板的质量：标定板需要具有较高的精度和稳定性，以保证提取的角点准确无误。同时，在摄影过程中需要避免标定板发生变形或损坏。\n",
    "2.角点提取算法：角点提取算法需要能够精确地检测到标定板上的特征点，并且对噪声和光照变化具有一定的鲁棒性。目前常用的角点提取算法包括Harris角点算法、Shi-Tomasi算法等。\n",
    "3.图像采集：在采集图像时，应尽可能保持相机姿态的多样性和分布均匀性，以覆盖尽可能广泛的空间。\n",
    "4.相机位姿的估计：相机位姿的估计需要具有一定的精度和可靠性。通常可以使用三维-二维点对求解相机姿态，也可以使用直接法等方法进行位姿估计。\n",
    "5.重投影误差的评估：重投影误差是评估标定结果好坏的一个重要指标。在评估时，需要注意将误差控制在一定范围内，同时了解误差来源，以便对标定结果进行进一步优化。\n",
    "6.畸变校正的效果：畸变是相机成像过程中不可避免的问题，需要进行畸变校正。在进行畸变校正时，需要注意调整参数以达到最佳校正效果，并对校正结果进行评估和验证。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义棋盘格模板规格:只算内角点个数,不算最外面的一圈点\n",
    "pattern_size = (11, 8)\n",
    "# 定义每个棋盘格的物理尺寸（单位：毫米）\n",
    "square_size = 40.0\n",
    "# 图像所在文件夹的位置\n",
    "original_images = './CalibrationPlate/original/'   # 原始图片保存位置\n",
    "resize_images = './CalibrationPlate/resize/'   # 调整尺寸后的图像保存位置\n",
    "corner_images = './CalibrationPlate/corner/'   # 显示角点的图像保存位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"_调整图片大小,防止图片过大引起崩溃_\n",
    "Args:\n",
    "    input (_string_): _输入图片的文件夹路径_\n",
    "    output (_string_): _输出图片的文件夹路径_\n",
    "    width (_int_): _输出图片宽度_\n",
    "    height (_int_): _输出图片高度_\n",
    "\"\"\"\n",
    "def ResizeImage(input, output, width, height):\n",
    "    Images = os.listdir(input)\n",
    "    for fname in Images:\n",
    "        image = cv2.imread(input + fname)\n",
    "        out = cv2.resize(image, (width, height))\n",
    "        cv2.imwrite(output + fname, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整图片尺寸\n",
    "new_width = 800\n",
    "new_height = 600\n",
    "ResizeImage(original_images, resize_images, new_width, new_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 世界坐标系中的棋盘格点,例如(0,0,0),(2,0,0)...(8,5,0)，去掉Z坐标，记为二维矩阵\n",
    "world_point = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "# 将世界坐标系建在标定板上，所有点的Z坐标全部为0，所以只需要赋值x和y\n",
    "world_point[:, :2] = np.mgrid[0:pattern_size[0]*square_size:square_size,\n",
    "                              0:pattern_size[1]*square_size:square_size].T.reshape(-1, 2)\n",
    "# 储存棋盘格角点的世界坐标和图像坐标对\n",
    "world_points = []  # 世界坐标系中的三维点\n",
    "image_points = []  # 图像平面的二维点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "角点精准化迭代过程的终止条件:\n",
    "第一项:表示迭代次数达到最大次数时停止迭代;\n",
    "第二项:表示角点位置变化的最小值已经达到最小时停止迭代;\n",
    "第三项和第四项：表示设置寻找亚像素角点的参数--采用的停止准则是最大循环次数30和最大误差容限0.001\n",
    "\"\"\"\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,\n",
    "            30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = os.listdir(resize_images)   # 读入图像序列\n",
    "index = 0\n",
    "for fname in images:\n",
    "    image = cv2.imread(resize_images + '/' + fname)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)   # RGB转灰度\n",
    "    # 寻找棋盘格角点,存放角点于corners中\n",
    "    # 如果找到足够点对,将其存储起来,ret为非零值\n",
    "    ret, corners = cv2.findChessboardCorners(gray, pattern_size, None)\n",
    "    # 检测到角点后,进行亚像素级别角点检测,更新角点\n",
    "\n",
    "    if ret == True:\n",
    "        index += 1\n",
    "        # 输入图像gray;角点初始坐标corners;搜索窗口为2*winsize+1;表示窗口的最小(-1.-1)表示忽略;求角点的迭代终止条件\n",
    "        cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "        world_points.append(world_point)   # 世界坐标\n",
    "        image_points.append(corners)  # 图像坐标\n",
    "        cv2.drawChessboardCorners(image, pattern_size, corners, ret)\n",
    "        cv2.imwrite(corner_images + '/corners_' + str(index) + '.jpg', image)\n",
    "        cv2.waitKey(10)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ret(重投影误差): 0.2991705035712761 \n",
      "\n",
      "mtx(内参矩阵):\n",
      " [[596.34925072   0.         400.35710334]\n",
      " [  0.         596.49697012 300.47081541]\n",
      " [  0.           0.           1.        ]] \n",
      "\n",
      "dist(畸变参数):\n",
      " [[ 9.86732100e-02 -4.94565440e-01 -4.51708736e-04  2.89052555e-04\n",
      "   8.22459145e-01]] \n",
      "\n",
      "rvecs(旋转向量):\n",
      " (array([[-0.0483275 ],\n",
      "       [-0.05556281],\n",
      "       [ 0.00805537]]), array([[-0.12482361],\n",
      "       [ 0.15589444],\n",
      "       [-0.07529847]]), array([[-0.17208193],\n",
      "       [ 0.10014288],\n",
      "       [-0.37814094]]), array([[-0.12937114],\n",
      "       [ 0.11474067],\n",
      "       [ 0.48904626]]), array([[0.30262844],\n",
      "       [0.16153906],\n",
      "       [0.03016236]]), array([[0.01218194],\n",
      "       [0.56805057],\n",
      "       [0.0150598 ]]), array([[-0.02910297],\n",
      "       [-0.39260678],\n",
      "       [-0.02031562]]), array([[-0.27239019],\n",
      "       [-0.36934551],\n",
      "       [ 0.12117097]]), array([[ 0.22883962],\n",
      "       [-0.30550396],\n",
      "       [-0.12688241]]), array([[ 0.06883582],\n",
      "       [-0.27973277],\n",
      "       [-0.06456626]]), array([[-0.2665373 ],\n",
      "       [-0.18509018],\n",
      "       [ 0.38498412]]), array([[ 0.09783529],\n",
      "       [-0.21184964],\n",
      "       [-0.48961838]]), array([[ 0.22456139],\n",
      "       [ 0.00599968],\n",
      "       [-3.1315238 ]]), array([[-0.13385948],\n",
      "       [ 0.02546384],\n",
      "       [ 3.10821897]]), array([[-0.22103183],\n",
      "       [ 0.42966368],\n",
      "       [ 3.05841508]]), array([[-0.30544462],\n",
      "       [ 0.14871615],\n",
      "       [-0.00088896]]), array([[ 0.53408529],\n",
      "       [-0.0570036 ],\n",
      "       [-3.09405172]]), array([[-0.04959992],\n",
      "       [-0.10507676],\n",
      "       [-3.13857081]]), array([[-0.0972829 ],\n",
      "       [-0.08890497],\n",
      "       [ 0.01960093]]), array([[-0.04695007],\n",
      "       [-0.05096119],\n",
      "       [ 0.00242619]])) \n",
      "\n",
      "tvecs(平移向量):\n",
      " (array([[-204.38036057],\n",
      "       [-143.87274813],\n",
      "       [ 458.71932771]]), array([[-213.87714901],\n",
      "       [ -93.52995838],\n",
      "       [ 608.85313672]]), array([[-266.54826979],\n",
      "       [ -78.42825425],\n",
      "       [ 646.89869759]]), array([[-152.93155156],\n",
      "       [-240.75828012],\n",
      "       [ 661.87209829]]), array([[-197.74298386],\n",
      "       [-123.1924115 ],\n",
      "       [ 594.36893509]]), array([[-129.71632578],\n",
      "       [-118.62533247],\n",
      "       [ 764.41837656]]), array([[-221.05989621],\n",
      "       [-148.61904991],\n",
      "       [ 540.49973912]]), array([[-217.0764501 ],\n",
      "       [-193.13661952],\n",
      "       [ 629.49519481]]), array([[-226.35354843],\n",
      "       [ -99.73771379],\n",
      "       [ 506.13830709]]), array([[-335.83854856],\n",
      "       [-134.94291291],\n",
      "       [ 740.02920591]]), array([[-173.24131758],\n",
      "       [-253.85349732],\n",
      "       [ 718.31597378]]), array([[-252.65792958],\n",
      "       [ -18.3029677 ],\n",
      "       [ 625.863489  ]]), array([[177.17662622],\n",
      "       [125.25440728],\n",
      "       [548.07063397]]), array([[199.92803842],\n",
      "       [126.77537112],\n",
      "       [491.12429853]]), array([[217.85189441],\n",
      "       [109.72360073],\n",
      "       [540.82760842]]), array([[-202.16119271],\n",
      "       [-156.34730964],\n",
      "       [ 575.20001061]]), array([[182.57460575],\n",
      "       [136.73320244],\n",
      "       [579.14632475]]), array([[199.00350427],\n",
      "       [139.63081102],\n",
      "       [418.58651616]]), array([[-215.98159284],\n",
      "       [-131.89756103],\n",
      "       [ 536.78155315]]), array([[-210.25583411],\n",
      "       [-144.65904885],\n",
      "       [ 460.79459783]]))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "输入:世界坐标系里的位置;像素坐标;图像的像素尺寸大小;\n",
    "输出:\n",
    "    ret: 重投影误差;\n",
    "    mtx: 内参矩阵;\n",
    "    dist: 畸变系数;\n",
    "    rvecs: 旋转向量 (外参数);\n",
    "    tvecs: 平移向量 (外参数);\n",
    "\"\"\"\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    world_points, image_points, gray.shape[::-1], None, None)\n",
    "\n",
    "# 保存相机参数(内参矩阵、畸变参数、旋转向量、平移向量)\n",
    "np.savez('./Parameter/豪威OV48B.npz', mtx=mtx, dist=dist,\n",
    "         rvecs=rvecs, tvecs=tvecs)  # 分别使用mtx,dist,rvecs,tvecs命名数组\n",
    "\n",
    "print(\"ret(重投影误差):\", ret,\n",
    "      \"\\n\\nmtx(内参矩阵):\\n\", mtx,\n",
    "      \"\\n\\ndist(畸变参数):\\n\", dist,  # 5个畸变参数,(k1,k2,p1,p2,k3)\n",
    "      \"\\n\\nrvecs(旋转向量):\\n\", rvecs,\n",
    "      \"\\n\\ntvecs(平移向量):\\n\", tvecs\n",
    "      )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取Aruco码中心点的像素坐标\n",
    "\n",
    "#### 方法原理\n",
    "```\n",
    "检测所拍摄的含有ArUco标记的图像,识别出每个ArUco码标记的中心点,在获取四个角点的像素坐标后计算出中心点的像素坐标\n",
    "```\n",
    "\n",
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载用于生成标记的字典\n",
    "dictionary = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_250)\n",
    "# 使用默认值初始化检测器参数\n",
    "parameters = cv2.aruco.DetectorParameters_create()\n",
    "\n",
    "index=0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据两幅图像和对应的四个点的三维世界坐标和二维像素坐标来求其他点的世界坐标\n",
    "#### 要求已知\n",
    "```\n",
    "1.两幅图像上对应的四个点的世界坐标和像素坐标。\n",
    "2.相机的内参矩阵和畸变系数。\n",
    "```\n",
    "#### 实现方法\n",
    "```\n",
    "使用立体视觉（stereo vision）的方法：首先计算两个相机的姿态（旋转和平移矩阵），然后使用这些矩阵和相机内参矩阵进行三角测量（triangulation）以获取其他点的世界坐标。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导包\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用PnP算法估计相机姿态\n",
    "def estimate_camera_pose(world_coords, pixel_coords, camera_matrix, dist_coeffs):\n",
    "    _, rvec, tvec, _ = cv2.solvePnPRansac(\n",
    "        world_coords, pixel_coords, camera_matrix, dist_coeffs)\n",
    "    return rvec, tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三角测量计算世界坐标\n",
    "def triangulate_points(pixel_coords1, pixel_coords2, camera_matrix, rvec1, tvec1, rvec2, tvec2):\n",
    "    proj_matrix1 = np.dot(camera_matrix, np.hstack(\n",
    "        (cv2.Rodrigues(rvec1)[0], tvec1)))\n",
    "    proj_matrix2 = np.dot(camera_matrix, np.hstack(\n",
    "        (cv2.Rodrigues(rvec2)[0], tvec2)))\n",
    "    world_coords = cv2.triangulatePoints(\n",
    "        proj_matrix1, proj_matrix2, pixel_coords1.T, pixel_coords2.T).T\n",
    "    world_coords = (world_coords / world_coords[:, 3:])[:, :3]\n",
    "    return world_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两幅图像中对应的世界坐标和像素坐标\n",
    "world_coords_list = [\n",
    "    np.array([[-50, -50, 0], [-50, 50, 0], [50, -50, 0],\n",
    "             [50, 50, 0]], dtype=np.float32),\n",
    "    np.array([[-50, -50, 0], [-50, 50, 0], [50, -50, 0],\n",
    "             [50, 50, 0]], dtype=np.float32)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucrptmld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
